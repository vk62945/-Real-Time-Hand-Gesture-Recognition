# -Real-Time-Hand-Gesture-Recognition

**Real-Time Hand Gesture Recognition using MediaPipe, TensorFlow, and OpenCV**  
---
## ğŸ“– About  
This project lets you record hand movements, train a model, and recognize gestures in real time using your webcam.  
It uses **MediaPipe** to detect hand landmarks, **TensorFlow** to learn gesture patterns, and **OpenCV** to show live predictions.  

Complete pipeline: **Data Collection â†’ Model Training â†’ Real-Time Prediction**  
---
## ğŸ“‚ Project Structure  
### 1ï¸âƒ£ Data Collection â€“ `record_gesture_data.py`  
- Captures hand landmarks (x, y coordinates).  
- Saves them into CSV files inside `gesture_data/`.  
- Example: `wave.csv`, `handshake.csv`, `approach.csv`.  
### 2ï¸âƒ£ Model Training â€“ `train_gesture_model.py`  
- Loads all gesture CSV files.  
- Prepares dataset and one-hot encodes labels.  
- Builds and trains a simple neural network.  
- Saves:  
  - `gesture_model.h5` â†’ trained model.  
  - `gesture_labels.txt` â†’ gesture label mapping.  
### 3ï¸âƒ£ Real-Time Recognition â€“ `gesture_recognition.py`  
- Opens webcam and detects hand in real time.  
- Predicts gestures using trained model.  
- Displays hand skeleton + predicted gesture on screen.  
- Optionally records new gesture data.  
---
## ğŸ› ï¸ Tech Stack  
- Python 3.x  
- OpenCV (video capture + display)  
- MediaPipe (hand tracking)  
- TensorFlow / Keras (gesture classification)  
- NumPy, Pandas (data processing)  
---

